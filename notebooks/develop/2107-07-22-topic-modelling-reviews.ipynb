{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import string\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from langdetect import DetectorFactory\n",
    "from langdetect import detect\n",
    "from datetime import datetime\n",
    "\n",
    "DetectorFactory.seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Establishing Connection\n",
    "try:\n",
    "    conn = psycopg2.connect('''\n",
    "    dbname='brew' user='rthakur' \n",
    "    host='capstone-brewing.cyol5m7lekm6.us-east-1.rds.amazonaws.com' \n",
    "    password='brew'\n",
    "    ''')\n",
    "except:\n",
    "    print \"Unable to connect to the database\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Compiling Documents\n",
    "\n",
    "cur = conn.cursor()\n",
    "cur.execute(\"\"\"\n",
    "select b.id,\n",
    "       b.name,\n",
    "       r.text\n",
    "from wrk.beer b left join wrk.review r on b.id = r.beer_id\n",
    "where r.beer_id=2886\n",
    "\"\"\")\n",
    "rows = cur.fetchall()\n",
    "\n",
    "reviews = []\n",
    "for row in rows:\n",
    "    review = row[2].decode('utf-8')\n",
    "    try:\n",
    "        if detect(review)=='en':\n",
    "            reviews.append(review.lower())\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "## Cleaning and Preprocessing\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "additional_exclude_words = ['updated','really','good','bad', 'de']\n",
    "stop |= set(additional_exclude_words)\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc):\n",
    "    stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = \" \".join(lemma.lemmatize(word) for word in punc_free.split())\n",
    "    return normalized\n",
    "\n",
    "reviews_clean = [clean(r).split() for r in reviews]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the term dictionary of our corpus, where every unique term is assigned an index. \n",
    "dictionary = corpora.Dictionary(reviews_clean)\n",
    "\n",
    "# Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "rev_term_matrix = [dictionary.doc2bow(r) for r in reviews_clean]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-22 23:03:26.544000\n",
      "2017-07-22 23:12:07.535000\n"
     ]
    }
   ],
   "source": [
    "print str(datetime.now())\n",
    "# Creating the object for LDA model\n",
    "Lda = gensim.models.ldamodel.LdaModel\n",
    "\n",
    "# Running and Training LDA on the document term matrix.\n",
    "ldamodel = Lda(rev_term_matrix, num_topics=5, id2word = dictionary, passes=50)\n",
    "print str(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-22 23:12:37.834000\n",
      "[(0, u'0.031*\"dark\" + 0.030*\"head\" + 0.026*\"aroma\" + 0.026*\"brown\" + 0.022*\"fruit\"'), (1, u'0.010*\"beer\" + 0.006*\"chimay\" + 0.006*\"blue\" + 0.005*\"trappist\" + 0.005*\"rating\"'), (2, u'0.007*\"old\" + 0.005*\"yeast\" + 0.005*\"like\" + 0.005*\"nose\" + 0.004*\"chocolate\"'), (3, u'0.040*\"beer\" + 0.016*\"taste\" + 0.015*\"one\" + 0.012*\"flavor\" + 0.012*\"like\"'), (4, u'0.033*\"beer\" + 0.016*\"rated\" + 0.014*\"trappist\" + 0.013*\"via\" + 0.013*\"buddy\"')]\n",
      "2017-07-22 23:12:37.839000\n"
     ]
    }
   ],
   "source": [
    "print str(datetime.now())\n",
    "print ldamodel.print_topics(num_topics=5, num_words=5)\n",
    "print str(datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
