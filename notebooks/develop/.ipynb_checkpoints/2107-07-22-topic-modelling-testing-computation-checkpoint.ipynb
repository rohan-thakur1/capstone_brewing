{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rohan_000\\Anaconda2\\lib\\site-packages\\gensim\\utils.py:855: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "import psycopg2\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import nltk.tokenize as tk\n",
    "import nltk\n",
    "import string\n",
    "import gensim\n",
    "from gensim import corpora, models, similarities\n",
    "from langdetect import DetectorFactory\n",
    "from langdetect import detect\n",
    "from datetime import datetime\n",
    "\n",
    "DetectorFactory.seed = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Cleaning and Preprocessing\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "additional_exclude_words = [u'beer', u'one', u'like', u'well', u'really', u'very', u'it\\x92s', \n",
    "                            u'it', u'beers',u'would',u'taste',u'tastes',u'get',u'i\\x92m',u'quite', u'i\\x92ve',\n",
    "                            u'bit',u'much',u'good',u'better',u'think',u'first',u'new',u'try', u'updated']\n",
    "stop |= set(additional_exclude_words)\n",
    "exclude = set(string.punctuation) \n",
    "lemma = WordNetLemmatizer()\n",
    "def clean(doc, name_tokens):\n",
    "    #stop_free = \" \".join([i for i in doc.lower().split() if i not in stop])\n",
    "    punc_free = \" \".join([ch for ch in doc.lower().split() if ch not in exclude])\n",
    "    normalized = \" \".join([lemma.lemmatize(word) for word in punc_free.split()])\n",
    "    tokens = tk.word_tokenize(normalized)\n",
    "    tokens_with_pos = [x[0] for x in nltk.pos_tag(tokens) if x[1] in ('NN','JJ') and \n",
    "                       x[0] not in name_tokens and len(x[0])>2 and x[0] not in stop]\n",
    "    return tokens_with_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Establishing Connection\n",
    "try:\n",
    "    conn = psycopg2.connect('''\n",
    "    dbname='brew' user='rthakur' \n",
    "    host='capstone-brewing.cyol5m7lekm6.us-east-1.rds.amazonaws.com' \n",
    "    password='brew'\n",
    "    ''')\n",
    "except:\n",
    "    print \"Unable to connect to the database\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary.load('../../data/beerwords_v3.dict')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2017-08-08 00:34:24.676000\n",
      "500\n",
      "2017-08-08 01:22:38.817000\n",
      "1000\n",
      "2017-08-08 02:06:29.189000\n",
      "1500\n",
      "2017-08-08 02:58:29.450000\n",
      "2000\n",
      "2017-08-08 03:30:55.395000\n",
      "2500\n",
      "2017-08-08 04:21:36.843000\n",
      "3000\n",
      "2017-08-08 05:00:33.062000\n",
      "3500\n",
      "2017-08-08 05:55:52.559000\n",
      "4000\n",
      "2017-08-08 06:30:15.661000\n",
      "4500\n",
      "2017-08-08 07:01:50.972000\n"
     ]
    }
   ],
   "source": [
    "cur = conn.cursor()\n",
    "corpus = []\n",
    "\n",
    "for x in range(4611):\n",
    "    if x%500==0:\n",
    "        print x\n",
    "        print str(datetime.now())\n",
    "    cur.execute(\"\"\"\n",
    "    select b.id,\n",
    "       b.name,\n",
    "       r.text\n",
    "    from wrk.beer b left join wrk.review r on b.id = r.beer_id\n",
    "    where b.id={0}\n",
    "    \"\"\".format(x+1))\n",
    "    rows = cur.fetchall()\n",
    "    reviews_clean = []\n",
    "    for row in rows:\n",
    "        if not row[2]:\n",
    "            continue\n",
    "        review = row[2].decode('utf-8')\n",
    "        name = row[1]\n",
    "        name_tokens = nltk.word_tokenize(name.lower())\n",
    "        try:\n",
    "            if detect(review)=='en':\n",
    "                rev_clean = clean(review.lower(), name_tokens)\n",
    "                reviews_clean.extend(rev_clean)\n",
    "        except:\n",
    "            continue\n",
    "    corpus += [dictionary.doc2bow(reviews_clean)]\n",
    "    \n",
    "corpora.MmCorpus.serialize('../../data/beercorpus_v3.mm', corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-08-08 08:50:33.090000\n",
      "2017-08-08 08:57:00.064000\n"
     ]
    }
   ],
   "source": [
    "#corpus = corpora.MmCorpus('../../data/beercorpus_v3.mm')\n",
    "\n",
    "print str(datetime.now())\n",
    "beer_model =  models.LdaModel(corpus, id2word=dictionary, num_topics=200)\n",
    "print str(datetime.now())\n",
    "\n",
    "beer_model.save('../../data/beer_model_v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Similarity\n",
    "index = similarities.MatrixSimilarity(beer_model[corpus])\n",
    "kernel_estout = beer_model[corpus[2853]]\n",
    "like_kernel = sorted(list(enumerate(index[kernel_estout])), key = lambda x:x[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'show_topics'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-c2f010cb593c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mbeer_model\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2853\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'show_topics'"
     ]
    }
   ],
   "source": [
    "print like_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
